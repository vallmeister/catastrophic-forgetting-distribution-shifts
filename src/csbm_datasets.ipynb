{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f7226c-cdfc-419b-8715-7873af2e806e",
   "metadata": {},
   "source": [
    "# Creating, saving and loading datasets with CSBMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a703347a-575c-4248-9fcb-0e1f8090e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from csbms import MultiClassCSBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc4ccb4-99d1-41dd-90fd-4da2e343f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=3)\n",
    "csbm = MultiClassCSBM(n=8, classes=2, dimensions=4)\n",
    "data_list = [csbm.data]\n",
    "for i in range(4):\n",
    "    csbm.evolve()\n",
    "    data_list.append(csbm.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecf80d-3175-4558-bcb9-f420fc0c8065",
   "metadata": {},
   "source": [
    "## Simply by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d15efd7-9d9b-4050-b86f-ec013786de79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_0   | features: tensor([-0.256, -0.067,  1.231,  1.374])         |class: 1 \n",
      "node_1   | features: tensor([-0.045,  0.196,  0.897,  0.614])         |class: 1 \n",
      "node_2   | features: tensor([-0.537, -0.399,  0.789,  0.633])         |class: 1 \n",
      "node_3   | features: tensor([-0.130, -0.394,  1.002, -0.165])         |class: 1 \n",
      "node_4   | features: tensor([ 0.220, -0.155,  0.924,  0.133])         |class: 1 \n",
      "node_5   | features: tensor([0.337, 0.146, 1.133, 0.192])             |class: 1 \n",
      "node_6   | features: tensor([ 1.377,  0.744, -0.039,  0.019])         |class: 0 \n",
      "node_7   | features: tensor([0.144, 0.033, 0.733, 0.771])             |class: 1 \n",
      "node_8   | features: tensor([ 1.056,  0.809, -0.357, -0.215])         |class: 0 \n",
      "node_9   | features: tensor([ 0.331,  1.148,  0.207, -0.141])         |class: 0 \n",
      "node_10  | features: tensor([ 1.049,  0.943, -0.203,  0.367])         |class: 0 \n",
      "node_11  | features: tensor([ 0.725,  0.515, -0.208, -0.297])         |class: 0 \n",
      "node_12  | features: tensor([0.076, 0.682, 0.702, 0.444])             |class: 1 \n",
      "node_13  | features: tensor([ 0.487,  0.433,  0.084, -0.250])         |class: 0 \n",
      "node_14  | features: tensor([0.234, 0.214, 0.923, 1.258])             |class: 1 \n",
      "node_15  | features: tensor([-0.164, -0.530,  0.230,  0.709])         |class: 1 \n",
      "node_16  | features: tensor([0.987, 0.661, 0.022, 0.174])             |class: 0 \n",
      "node_17  | features: tensor([ 0.635,  0.588, -0.170, -0.021])         |class: 0 \n",
      "node_18  | features: tensor([-0.159,  0.142,  0.922,  0.771])         |class: 1 \n",
      "node_19  | features: tensor([ 0.683,  0.912,  0.414, -0.372])         |class: 0 \n",
      "node_20  | features: tensor([-0.158,  0.278,  0.839,  1.056])         |class: 1 \n",
      "node_21  | features: tensor([ 0.863,  0.329, -0.513,  0.429])         |class: 0 \n",
      "node_22  | features: tensor([ 0.832,  0.328, -0.342, -0.140])         |class: 0 \n",
      "node_23  | features: tensor([0.124, 0.332, 0.687, 0.762])             |class: 1 \n",
      "node_24  | features: tensor([0.030, 0.014, 1.444, 1.635])             |class: 1 \n",
      "node_25  | features: tensor([-0.424,  0.221,  0.241,  0.801])         |class: 1 \n",
      "node_26  | features: tensor([-0.323, -0.087,  0.698,  1.160])         |class: 1 \n",
      "node_27  | features: tensor([ 0.732,  1.014, -0.487, -0.314])         |class: 0 \n",
      "node_28  | features: tensor([-0.256,  0.178,  1.138,  1.246])         |class: 1 \n",
      "node_29  | features: tensor([0.214, 0.720, 0.254, 0.144])             |class: 0 \n",
      "node_30  | features: tensor([ 0.504, -0.519,  1.136,  0.845])         |class: 1 \n",
      "node_31  | features: tensor([ 0.735,  0.394,  0.798, -0.102])         |class: 0 \n",
      "node_32  | features: tensor([-0.101, -0.017,  0.498,  0.687])         |class: 1 \n",
      "node_33  | features: tensor([0.128, 0.453, 0.966, 0.245])             |class: 1 \n",
      "node_34  | features: tensor([ 0.911,  0.336, -0.143, -0.377])         |class: 0 \n",
      "node_35  | features: tensor([0.573, 0.636, 0.173, 0.120])             |class: 0 \n",
      "node_36  | features: tensor([0.811, 0.584, 0.538, 0.419])             |class: 0 \n",
      "node_37  | features: tensor([ 0.552, -0.544,  0.868,  0.846])         |class: 1 \n",
      "node_38  | features: tensor([ 0.191, -0.156,  0.617,  0.955])         |class: 1 \n",
      "node_39  | features: tensor([-0.392, -0.542,  1.015,  0.902])         |class: 1 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_list[-1].x)):\n",
    "    print(f'node_{i}'.ljust(8), f'| features: {csbm.data.x[i]}'.ljust(60), f'|class: {csbm.data.y[i]}'.ljust(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3bf5e08-87c9-4f30-a324-472a551a0a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_0   | features: tensor([-0.256, -0.067,  1.231,  1.374])         |class: 1 \n",
      "node_1   | features: tensor([-0.045,  0.196,  0.897,  0.614])         |class: 1 \n",
      "node_2   | features: tensor([-0.537, -0.399,  0.789,  0.633])         |class: 1 \n",
      "node_3   | features: tensor([-0.130, -0.394,  1.002, -0.165])         |class: 1 \n",
      "node_4   | features: tensor([ 0.220, -0.155,  0.924,  0.133])         |class: 1 \n",
      "node_5   | features: tensor([0.337, 0.146, 1.133, 0.192])             |class: 1 \n",
      "node_6   | features: tensor([ 1.377,  0.744, -0.039,  0.019])         |class: 0 \n",
      "node_7   | features: tensor([0.144, 0.033, 0.733, 0.771])             |class: 1 \n",
      "node_8   | features: tensor([ 1.056,  0.809, -0.357, -0.215])         |class: 0 \n",
      "node_9   | features: tensor([ 0.331,  1.148,  0.207, -0.141])         |class: 0 \n",
      "node_10  | features: tensor([ 1.049,  0.943, -0.203,  0.367])         |class: 0 \n",
      "node_11  | features: tensor([ 0.725,  0.515, -0.208, -0.297])         |class: 0 \n",
      "node_12  | features: tensor([0.076, 0.682, 0.702, 0.444])             |class: 1 \n",
      "node_13  | features: tensor([ 0.487,  0.433,  0.084, -0.250])         |class: 0 \n",
      "node_14  | features: tensor([0.234, 0.214, 0.923, 1.258])             |class: 1 \n",
      "node_15  | features: tensor([-0.164, -0.530,  0.230,  0.709])         |class: 1 \n",
      "node_16  | features: tensor([0.987, 0.661, 0.022, 0.174])             |class: 0 \n",
      "node_17  | features: tensor([ 0.635,  0.588, -0.170, -0.021])         |class: 0 \n",
      "node_18  | features: tensor([-0.159,  0.142,  0.922,  0.771])         |class: 1 \n",
      "node_19  | features: tensor([ 0.683,  0.912,  0.414, -0.372])         |class: 0 \n",
      "node_20  | features: tensor([-0.158,  0.278,  0.839,  1.056])         |class: 1 \n",
      "node_21  | features: tensor([ 0.863,  0.329, -0.513,  0.429])         |class: 0 \n",
      "node_22  | features: tensor([ 0.832,  0.328, -0.342, -0.140])         |class: 0 \n",
      "node_23  | features: tensor([0.124, 0.332, 0.687, 0.762])             |class: 1 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_list[2].x)):\n",
    "    print(f'node_{i}'.ljust(8), f'| features: {csbm.data.x[i]}'.ljust(60), f'|class: {csbm.data.y[i]}'.ljust(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "410c649c-a241-45e1-beda-7bb219984544",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(data_list):\n",
    "    torch.save(data, f'./data_object_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e220326-b554-41bc-be46-9ca1803adca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_objects = []\n",
    "for i in range(5):\n",
    "    data = torch.load(f'./data_object_{i}.pt')\n",
    "    data_objects.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db80bb48-3656-4720-bcc4-130da2123f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_0   | features: tensor([-0.256, -0.067,  1.231,  1.374])         |class: 1 \n",
      "node_1   | features: tensor([-0.045,  0.196,  0.897,  0.614])         |class: 1 \n",
      "node_2   | features: tensor([-0.537, -0.399,  0.789,  0.633])         |class: 1 \n",
      "node_3   | features: tensor([-0.130, -0.394,  1.002, -0.165])         |class: 1 \n",
      "node_4   | features: tensor([ 0.220, -0.155,  0.924,  0.133])         |class: 1 \n",
      "node_5   | features: tensor([0.337, 0.146, 1.133, 0.192])             |class: 1 \n",
      "node_6   | features: tensor([ 1.377,  0.744, -0.039,  0.019])         |class: 0 \n",
      "node_7   | features: tensor([0.144, 0.033, 0.733, 0.771])             |class: 1 \n",
      "node_8   | features: tensor([ 1.056,  0.809, -0.357, -0.215])         |class: 0 \n",
      "node_9   | features: tensor([ 0.331,  1.148,  0.207, -0.141])         |class: 0 \n",
      "node_10  | features: tensor([ 1.049,  0.943, -0.203,  0.367])         |class: 0 \n",
      "node_11  | features: tensor([ 0.725,  0.515, -0.208, -0.297])         |class: 0 \n",
      "node_12  | features: tensor([0.076, 0.682, 0.702, 0.444])             |class: 1 \n",
      "node_13  | features: tensor([ 0.487,  0.433,  0.084, -0.250])         |class: 0 \n",
      "node_14  | features: tensor([0.234, 0.214, 0.923, 1.258])             |class: 1 \n",
      "node_15  | features: tensor([-0.164, -0.530,  0.230,  0.709])         |class: 1 \n",
      "node_16  | features: tensor([0.987, 0.661, 0.022, 0.174])             |class: 0 \n",
      "node_17  | features: tensor([ 0.635,  0.588, -0.170, -0.021])         |class: 0 \n",
      "node_18  | features: tensor([-0.159,  0.142,  0.922,  0.771])         |class: 1 \n",
      "node_19  | features: tensor([ 0.683,  0.912,  0.414, -0.372])         |class: 0 \n",
      "node_20  | features: tensor([-0.158,  0.278,  0.839,  1.056])         |class: 1 \n",
      "node_21  | features: tensor([ 0.863,  0.329, -0.513,  0.429])         |class: 0 \n",
      "node_22  | features: tensor([ 0.832,  0.328, -0.342, -0.140])         |class: 0 \n",
      "node_23  | features: tensor([0.124, 0.332, 0.687, 0.762])             |class: 1 \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_objects[2].x)):\n",
    "    print(f'node_{i}'.ljust(8), f'| features: {csbm.data.x[i]}'.ljust(60), f'|class: {csbm.data.y[i]}'.ljust(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc64b7a-5e32-464d-8fb2-275642bacb50",
   "metadata": {},
   "source": [
    "## With In-Memory-Dataset-Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "591de959-6ecf-479f-82a3-82ed44c4ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dba44b07-fed7-4d2e-beb6-055e723ca679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_list, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data_list = data_list\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        data_list = self.data_list\n",
    "        self.save(data_list, self.processed_file_names[0])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        if idx >= self.len():\n",
    "            raise ValueError(\"Index is out of range.\")\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a31d00-c01d-4065-99e8-08d9f084859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'csbm\\\\processed\\\\data.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csbm_data \u001b[38;5;241m=\u001b[39m \u001b[43mMyOwnDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./csbm/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m, in \u001b[0;36mMyOwnDataset.__init__\u001b[1;34m(self, root, data_list, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m data_list\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform, pre_transform, pre_filter)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Users\\Productivity\\anaconda3\\envs\\cudanew\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:124\u001b[0m, in \u001b[0;36mInMemoryDataset.load\u001b[1;34m(self, path, data_cls)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m, data_cls: Type[BaseData] \u001b[38;5;241m=\u001b[39m Data):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the dataset from the file path :obj:`path`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# Backward compatibility.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         data \u001b[38;5;241m=\u001b[39m data_cls\u001b[38;5;241m.\u001b[39mfrom_dict(data)\n",
      "File \u001b[1;32mD:\\Users\\Productivity\\anaconda3\\envs\\cudanew\\lib\\site-packages\\torch\\serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mD:\\Users\\Productivity\\anaconda3\\envs\\cudanew\\lib\\site-packages\\torch\\serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mD:\\Users\\Productivity\\anaconda3\\envs\\cudanew\\lib\\site-packages\\torch\\serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'csbm\\\\processed\\\\data.pt'"
     ]
    }
   ],
   "source": [
    "csbm_data = MyOwnDataset(root='./csbm/', data_list=data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f97ba6c6-db58-4895-9107-15e2f4d89952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[16, 4], edge_index=[2, 0], y=[16], train_mask=[16], validation_mask=[16], test_mask=[16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csbm_data.get(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
